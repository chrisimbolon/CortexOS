üåê CortexOS ‚Äî Modular AI Microservices Platform

CortexOS is a high-performance AI orchestration platform built with a modern microservices architecture.
It provides a clean, scalable way to run LLMs, embeddings, RAG pipelines, metrics logging, and API integrations ‚Äî all fully containerized and production-ready.

This project is designed for real-world deployment, expandability, and developer ergonomics, making it perfect for:

AI/ML backend engineering

RAG-powered applications

LangChain-style LLM orchestration without the bloat

FastAPI microservice architecture

Portfolio-level demonstration of AI system design

Core Features
üß† 1. LLM Orchestration Service

Modular orchestration layer for any LLM provider (OpenAI, Groq, Anthropic, local models).

Built-in support for:

ChatCompletion abstraction

Model switching

Token usage tracking

Automatic cost estimation

Latency measurement

Pluggable backends for hybrid routing (OpenAI + Groq + Local inference).


üìö 2. Knowledge / RAG Service

Document ingestion (file upload or raw text)

Automatic text chunking

Embeddings generation via Embeddings Service

Vector search via:

pgvector (preferred)

JSON fallback for local dev

Top-K retrieval API

Extensible metadata support

Forms the foundation of a full RAG pipeline.